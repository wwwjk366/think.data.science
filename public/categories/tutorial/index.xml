<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tutorial on Think.Data.Science</title>
    <link>/categories/tutorial/</link>
    <description>Recent content in Tutorial on Think.Data.Science</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <copyright>{year}</copyright>
    <lastBuildDate>Thu, 05 Dec 2019 00:00:00 +0000</lastBuildDate>
    
	    <atom:link href="/categories/tutorial/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Authenticating AWS (Signature V4) in R using Python Backend</title>
      <link>/post/2019-12-05-authenticating-aws-signature-v4-in-r-using-python-backend/</link>
      <pubDate>Thu, 05 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019-12-05-authenticating-aws-signature-v4-in-r-using-python-backend/</guid>
      <description>


&lt;div id=&#34;intuition&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Intuition&lt;/h2&gt;
&lt;p&gt;I was working with an Elasticsearch project on AWS using Python and the &lt;code&gt;requests_aws4auth&lt;/code&gt; package worked like a charm for me. Never had any issue regarding the authentication (AWS V4 could be hard to work with sometimes). However, when I trying to create a Shiny app for my project, the problem emerged. I just couldn’t get the V4 auth to work with &lt;code&gt;httr&lt;/code&gt; in R. I tried &lt;code&gt;aws.signature&lt;/code&gt; package on &lt;a href=&#34;https://github.com/cloudyr/aws.signature&#34;&gt;Github&lt;/a&gt; but keep getting request header issues. Then I remembered that JJ Alaire from Rstudio created this amazing package &lt;code&gt;reticulate&lt;/code&gt; &lt;a href=&#34;https://rstudio.github.io/reticulate/&#34;&gt;(link)&lt;/a&gt; claiming the ability to import Python packages into R. Therefore I am intrigued to give it a try!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-syntax&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The Syntax&lt;/h2&gt;
&lt;p&gt;After install this package, the actually syntax is quite simple.&lt;/p&gt;
&lt;p&gt;Load the package and point it to the location of your Python (I’m using Ubuntu here):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(reticulate)
use_python(&amp;quot;/usr/local/bin/python&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then you can easily load and call Python functions! For example, a simple &lt;code&gt;listdir&lt;/code&gt; function from &lt;code&gt;os&lt;/code&gt; package:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;os &amp;lt;- import(&amp;quot;os&amp;quot;)
os$listdir(&amp;quot;.&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;index.html&amp;quot;   &amp;quot;featured.png&amp;quot; &amp;quot;index.Rmd&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;in-shiny&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;In Shiny&lt;/h2&gt;
&lt;p&gt;All I did was adding those to the &lt;code&gt;global.R&lt;/code&gt; script (the script I source first in &lt;code&gt;server.R&lt;/code&gt;)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;py_awsauth &amp;lt;- import(&amp;quot;requests_aws4auth&amp;quot;)
py_requests &amp;lt;- import(&amp;quot;requests&amp;quot;)

region &amp;lt;- &amp;#39;us-east-2&amp;#39;
service &amp;lt;- &amp;#39;execute-api&amp;#39;
credentials &amp;lt;- aws.signature::locate_credentials()
authr &amp;lt;- py_awsauth$AWS4Auth(credentials$key, credentials$secret, region, service, session_token=credentials$session_token)
url &amp;lt;- &amp;#39;https://.....&amp;#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see I am setting up the AWS connection using my local stored credentials. And the next step is to send HTTP request using Python &lt;code&gt;requests&lt;/code&gt; package.&lt;/p&gt;
&lt;p&gt;One thing to noticed is that you cannot use nested list for your payload as you would do that if you are using R &lt;code&gt;httr&lt;/code&gt; package. You have to create a Python dictionary object as your payload using &lt;code&gt;reticulate::py_dict()&lt;/code&gt; function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;
params &amp;lt;- reticulate::py_dict(c(&amp;quot;x&amp;quot;, &amp;quot;y&amp;quot;),
                              c(...,...))
response &amp;lt;- py_requests$get(url, auth = authr,params = params)
res &amp;lt;- response$json()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It worked like magic!&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/14udF3WUwwGMaA/giphy.gif&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;thoughts&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Thoughts&lt;/h2&gt;
&lt;p&gt;This is a good example of why I always encouraging Data Scientist to learn both R and Python. Many people only proficient in one and often has biased opinion against the other. Why not learn both so you can use the amazing package in R like &lt;code&gt;shiny&lt;/code&gt; and equivalently amazing packages like &lt;code&gt;ortools&lt;/code&gt; (I will write another post on this) at the same time!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Preprocess Text in Python --- A Cleaner and Faster Approach</title>
      <link>/post/preprocess-your-text-for-nlp-models-cleaner/</link>
      <pubDate>Thu, 04 Jul 2019 20:14:43 +0000</pubDate>
      
      <guid>/post/preprocess-your-text-for-nlp-models-cleaner/</guid>
      <description>

&lt;h2 id=&#34;motivation&#34;&gt;Motivation&lt;/h2&gt;

&lt;p&gt;Well, I think it all start with one of my favorite tweets from 2013:&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;en&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;In Data Science, 80% of time spent prepare data, 20% of time spent complain about need for prepare data.&lt;/p&gt;&amp;mdash; Big Data Borat (@BigDataBorat) &lt;a href=&#34;https://twitter.com/BigDataBorat/status/306596352991830016?ref_src=twsrc%5Etfw&#34;&gt;February 27, 2013&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;When building NLP models, pre-processing your data is extremely important. For example, different stopwords removal, stemming and lemmization might have huge impact on the accuracy of your models. Often times, the order of how you do the cleaning is also critical. Do you want to remove certain words first then tokenize the text? Or tokenize then remove the tokens? What we need is a &lt;strong&gt;clear to understand&lt;/strong&gt; and yet &lt;strong&gt;flexiable&lt;/strong&gt; code to do the pre-processing job. When using R, the pipe operator &lt;code&gt;%&amp;gt;%&lt;/code&gt; kind of taken care of the most part. However, there is no really good equivlent in Python because the natural different of Python and R: &lt;a href=&#34;https://medium.com/@jondot/functional-programming-with-python-for-people-without-time-1eebdbd9526c&#34; target=&#34;_blank&#34;&gt;(Long but very good read)&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;In other words, it’s like saying that when OOP was born, it was also born with the Gang-of-Four design patterns baked into it’s core as its backing theory of thought (outside of types and inheritance and methods etc.), and every implemented OOP language included these patterns and abstractions by default for you to take advantage of, and that these patterns were bullet-proofed by centuries of research. But that can already never be correct — the Singleton pattern is by now widely recognized as an anti-pattern, and GoF authors said they would remove it, if only they could go back in time.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;But we can definitely hack our way around this using Python &lt;strong&gt;Class&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;design&#34;&gt;Design&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s create a snippet of text as an example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;sample = &amp;quot;&amp;quot;&amp;quot;&amp;lt;h1&amp;gt;Title Goes Here&amp;lt;/h1&amp;gt;
&amp;lt;b&amp;gt;Bolded Text&amp;lt;/b&amp;gt;
&amp;lt;i&amp;gt;Italicized Text&amp;lt;/i&amp;gt;
&amp;lt;img src=&amp;quot;this should all be gone&amp;quot;/&amp;gt;
&amp;lt;a href=&amp;quot;this will be gone, too&amp;quot;&amp;gt;But this will still be here!&amp;lt;/a&amp;gt;
I run. He ran. She is running. Will they stop running?
I talked. She was talking. They talked to them about running. Who ran to the talking runner?
[Some text we don&#39;t want to keep is in here]
¡Sebastián, Nicolás, Alejandro and Jéronimo are going to the store tomorrow morning!
something... is! wrong() with.,; this :: sentence.
I can&#39;t do this anymore. I didn&#39;t know them. Why couldn&#39;t you have dinner at the restaurant?
My favorite movie franchises, in order: Indiana Jones; Marvel Cinematic Universe; Star Wars; Back to the Future; Harry Potter.
Don&#39;t do it.... Just don&#39;t. Billy! I know what you&#39;re doing. This is a great little house you&#39;ve got here.
[This is some other unwanted text]
John: &amp;quot;Well, well, well.&amp;quot;
James: &amp;quot;There, there. There, there.&amp;quot;
&amp;amp;nbsp;&amp;amp;nbsp;
There are a lot of reasons not to do this. There are 101 reasons not to do it. 1000000 reasons, actually.
I have to go get 2 tutus from 2 different stores, too.
22    45   1067   445
{{Here is some stuff inside of double curly braces.}}
{Here is more stuff in single curly braces.}
[DELETE]
&amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;&amp;quot;&amp;quot;&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Say you want to strip some html characters and use regular expressions to remove open and close double brackets and anything in between them:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import re, string, unicodedata
from bs4 import BeautifulSoup

def strip_html(text):
    soup = BeautifulSoup(text, &amp;quot;html.parser&amp;quot;)
    return soup.get_text()

def remove_between_square_brackets(text):
    return re.sub(&#39;\[[^]]*\]&#39;, &#39;&#39;, text)

def denoise_text(text):
    text = strip_html(text)
    text = remove_between_square_brackets(text)
    return text

sample = denoise_text(sample)
print(sample)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;    Title Goes Here
    Bolded Text
    Italicized Text
    
    But this will still be here!
    I run. He ran. She is running. Will they stop running?
    I talked. She was talking. They talked to them about running. Who ran to the talking runner?
    
    ¡Sebastián, Nicolás, Alejandro and Jéronimo are going to the store tomorrow morning!
    something... is! wrong() with.,; this :: sentence.
    I can&#39;t do this anymore. I didn&#39;t know them. Why couldn&#39;t you have dinner at the restaurant?
    My favorite movie franchises, in order: Indiana Jones; Marvel Cinematic Universe; Star Wars; Back to the Future; Harry Potter.
    Don&#39;t do it.... Just don&#39;t. Billy! I know what you&#39;re doing. This is a great little house you&#39;ve got here.
    
    John: &amp;quot;Well, well, well.&amp;quot;
    James: &amp;quot;There, there. There, there.&amp;quot;
    
    There are a lot of reasons not to do this. There are 101 reasons not to do it. 1000000 reasons, actually.
    I have to go get 2 tutus from 2 different stores, too.
    22    45   1067   445
    {{Here is some stuff inside of double curly braces.}}
     {Here is more stuff in single curly braces.}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This perfectly demonstrates our normal workflow:
1. Define couple of functions like &lt;code&gt;strip_html()&lt;/code&gt;, &lt;code&gt;remove_punctuation()&lt;/code&gt; &amp;hellip;
2. Run them one by one or define another &amp;ldquo;master function&amp;rdquo; to run them all like above example
3. Found that we need add more functions or change the order of the function runs
4. Make changes to the &amp;ldquo;master function&amp;rdquo; by copy and paste, then re-define it
5. Run new &amp;ldquo;master function&amp;rdquo; on the text
6. Rinse and repeat&lt;/p&gt;

&lt;p&gt;It is not very flexiable and easy to maintain, isn&amp;rsquo;t it?&lt;/p&gt;

&lt;h2 id=&#34;solution&#34;&gt;Solution&lt;/h2&gt;

&lt;p&gt;If we put those functions in a Class and let the function return &lt;code&gt;self&lt;/code&gt;, we can use the dot notation &lt;code&gt;.&lt;/code&gt; to chain them together, at any order!&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class cleantext():
    
    def __init__(self, text = None):
        self.text = text
        
    def strip_html(self):
        soup = BeautifulSoup(self.text, &amp;quot;html.parser&amp;quot;)
        self.text = soup.get_text()
        return self

    def remove_between_square_brackets(self):
        self.text = re.sub(&#39;\[[^]]*\]&#39;, &#39;&#39;, self.text)
        return self

    def remove_numbers(self):
        self.text = re.sub(&#39;[-+]?[0-9]+&#39;, &#39;&#39;, self.text)
        return self
    
    def do_all(self, text):
        
        self.text = text
        self = self.strip_html()
        self = self.remove_numbers()
       
        return self.words


&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;ct = cleantext(sample)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print(ct.strip_html().remove_between_square_brackets().remove_numbers().text)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;    Title Goes Here
    Bolded Text
    Italicized Text
    
    But this will still be here!
    I run. He ran. She is running. Will they stop running?
    I talked. She was talking. They talked to them about running. Who ran to the talking runner?
    
    ¡Sebastián, Nicolás, Alejandro and Jéronimo are going to the store tomorrow morning!
    something... is! wrong() with.,; this :: sentence.
    I can&#39;t do this anymore. I didn&#39;t know them. Why couldn&#39;t you have dinner at the restaurant?
    My favorite movie franchises, in order: Indiana Jones; Marvel Cinematic Universe; Star Wars; Back to the Future; Harry Potter.
    Don&#39;t do it.... Just don&#39;t. Billy! I know what you&#39;re doing. This is a great little house you&#39;ve got here.
    
    John: &amp;quot;Well, well, well.&amp;quot;
    James: &amp;quot;There, there. There, there.&amp;quot;
    
    There are a lot of reasons not to do this. There are  reasons not to do it.  reasons, actually.
    I have to go get  tutus from  different stores, too.
              
    {{Here is some stuff inside of double curly braces.}}
    {Here is more stuff in single curly braces.}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This makes our code readable and easy to manipulate. We can read out our code too &amp;mdash; just read the dot &lt;code&gt;.&lt;/code&gt; as &amp;ldquo;then&amp;rdquo; in your mind :
&amp;gt; sample text &lt;strong&gt;then&lt;/strong&gt; strip html &lt;strong&gt;then&lt;/strong&gt; remove between square brackets &lt;strong&gt;then&lt;/strong&gt; remove numbers&amp;rdquo;&lt;/p&gt;

&lt;h2 id=&#34;full-implementation&#34;&gt;Full implementation&lt;/h2&gt;

&lt;p&gt;So my full definition of the class looks like this: (example and many functions are from KDNugget)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import re, string, unicodedata
import nltk
import contractions
import inflect
from bs4 import BeautifulSoup
from nltk import word_tokenize, sent_tokenize
from nltk.corpus import stopwords
from nltk.stem import LancasterStemmer, WordNetLemmatizer

class cleantext():
    
    def __init__(self, text = &amp;quot;test&amp;quot;):
        self.text = text
        
    def strip_html(self):
        soup = BeautifulSoup(self.text, &amp;quot;html.parser&amp;quot;)
        self.text = soup.get_text()
        return self

    def remove_between_square_brackets(self):
        self.text = re.sub(&#39;\[[^]]*\]&#39;, &#39;&#39;, self.text)
        return self

    def remove_numbers(self):
        self.text = re.sub(&#39;[-+]?[0-9]+&#39;, &#39;&#39;, self.text)
        return self

    def replace_contractions(self):
        &amp;quot;&amp;quot;&amp;quot;Replace contractions in string of text&amp;quot;&amp;quot;&amp;quot;
        self.text = contractions.fix(self.text)
        return self
    
    def get_words(self):
        self.words = nltk.word_tokenize(self.text)
        return self

    def remove_non_ascii(self):
        &amp;quot;&amp;quot;&amp;quot;Remove non-ASCII characters from list of tokenized words&amp;quot;&amp;quot;&amp;quot;
        new_words = []
        for word in self.words:
            new_word = unicodedata.normalize(&#39;NFKD&#39;, word).encode(&#39;ascii&#39;, &#39;ignore&#39;).decode(&#39;utf-8&#39;, &#39;ignore&#39;)
            new_words.append(new_word)
        self.words = new_words
        return self

    def to_lowercase(self):
        &amp;quot;&amp;quot;&amp;quot;Convert all characters to lowercase from list of tokenized words&amp;quot;&amp;quot;&amp;quot;
        new_words = []
        for word in self.words:
            new_word = word.lower()
            new_words.append(new_word)
        self.words = new_words
        return self

    def remove_punctuation(self):
        &amp;quot;&amp;quot;&amp;quot;Remove punctuation from list of tokenized words&amp;quot;&amp;quot;&amp;quot;
        new_words = []
        for word in self.words:
            new_word = re.sub(r&#39;[^\w\s]&#39;, &#39;&#39;, word)
            if new_word != &#39;&#39;:
                new_words.append(new_word)
        self.words = new_words
        return self

    def replace_numbers(self):
        &amp;quot;&amp;quot;&amp;quot;Replace all interger occurrences in list of tokenized words with textual representation&amp;quot;&amp;quot;&amp;quot;
        p = inflect.engine()
        new_words = []
        for word in self.words:
            if word.isdigit():
                new_word = p.number_to_words(word)
                new_words.append(new_word)
            else:
                new_words.append(word)
        self.words = new_words
        return self

    def remove_stopwords(self):
        &amp;quot;&amp;quot;&amp;quot;Remove stop words from list of tokenized words&amp;quot;&amp;quot;&amp;quot;
        new_words = []
        for word in self.words:
            if word not in stopwords.words(&#39;english&#39;):
                new_words.append(word)
        self.words = new_words
        return self

    def stem_words(self):
        &amp;quot;&amp;quot;&amp;quot;Stem words in list of tokenized words&amp;quot;&amp;quot;&amp;quot;
        stemmer = LancasterStemmer()
        stems = []
        for word in self.words:
            stem = stemmer.stem(word)
            stems.append(stem)
        self.words = stems
        return self

    def lemmatize_verbs(self):
        &amp;quot;&amp;quot;&amp;quot;Lemmatize verbs in list of tokenized words&amp;quot;&amp;quot;&amp;quot;
        lemmatizer = WordNetLemmatizer()
        lemmas = []
        for word in self.words:
            lemma = lemmatizer.lemmatize(word, pos=&#39;v&#39;)
            lemmas.append(lemma)
        self.words = lemmas
        return self
    
    def join_words(self):
        self.words = &#39; &#39;.join(self.words)
        return self
    
    def do_all(self, text):
        
        self.text = text
        self = self.strip_html()
        self = self.remove_numbers()
        self = self.replace_contractions()
        self = self.get_words()
        self = self.remove_punctuation()
        self = self.remove_non_ascii()
        self = self.remove_stopwords()
        self = self.stem_words()
        self = self.lemmatize_verbs()
        self = self.join_words()
        
        return self.words
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we can pre-process our text easily, in a chain-like matter:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;ct = cleantext(sample)

ct.\
strip_html().\
remove_numbers().\
replace_contractions().\
get_words().\
remove_punctuation().\
remove_non_ascii().\
remove_stopwords().\
stem_words().\
lemmatize_verbs().\
join_words().\
words
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;&#39;titl goe her bold text it text but stil i run he run she run wil stop run i talk she talk they talk run who run talk run som text want keep sebast nicola alejandro jeronimo go stor tomorrow morn someth wrong send i anym i know why could din resta my favorit movy franch ord indian jon marvel cinem univers star war back fut harry pot just bil i know thi gre littl hous get thi unw text john wel wel wel jam ther ther ther lot reason ther reason reason act i go get tut diff stor her stuff insid doubl cur brac her stuff singl cur brac delet&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can easily add or modify any step on your code, it&amp;rsquo;s like a pipeline!&lt;/p&gt;

&lt;h2 id=&#34;apply-on-pandas-dataframe&#34;&gt;Apply on Pandas DataFrame&lt;/h2&gt;

&lt;p&gt;Say right now we have a dataframe and one column contains the string we would like to process. We can easily use &lt;code&gt;apply()&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import pandas as pd
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df = pd.DataFrame({&#39;id&#39;: range(0,100), &#39;docs&#39;:sample } )
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df.head()
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;id&lt;/th&gt;
      &lt;th&gt;docs&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;&amp;lt;h1&amp;gt;Title Goes Here&amp;lt;/h1&amp;gt;\n&amp;lt;b&amp;gt;Bolded Text&amp;lt;/b&amp;gt;\n...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;&amp;lt;h1&amp;gt;Title Goes Here&amp;lt;/h1&amp;gt;\n&amp;lt;b&amp;gt;Bolded Text&amp;lt;/b&amp;gt;\n...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;&amp;lt;h1&amp;gt;Title Goes Here&amp;lt;/h1&amp;gt;\n&amp;lt;b&amp;gt;Bolded Text&amp;lt;/b&amp;gt;\n...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;&amp;lt;h1&amp;gt;Title Goes Here&amp;lt;/h1&amp;gt;\n&amp;lt;b&amp;gt;Bolded Text&amp;lt;/b&amp;gt;\n...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;&amp;lt;h1&amp;gt;Title Goes Here&amp;lt;/h1&amp;gt;\n&amp;lt;b&amp;gt;Bolded Text&amp;lt;/b&amp;gt;\n...&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df[&#39;cleaned_docs&#39;] = df[&#39;docs&#39;].apply(ct.do_all)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df.head()
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;id&lt;/th&gt;
      &lt;th&gt;docs&lt;/th&gt;
      &lt;th&gt;cleaned_docs&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;&amp;lt;h1&amp;gt;Title Goes Here&amp;lt;/h1&amp;gt;\n&amp;lt;b&amp;gt;Bolded Text&amp;lt;/b&amp;gt;\n...&lt;/td&gt;
      &lt;td&gt;titl goe her bold text it text but stil i run ...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;&amp;lt;h1&amp;gt;Title Goes Here&amp;lt;/h1&amp;gt;\n&amp;lt;b&amp;gt;Bolded Text&amp;lt;/b&amp;gt;\n...&lt;/td&gt;
      &lt;td&gt;titl goe her bold text it text but stil i run ...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;&amp;lt;h1&amp;gt;Title Goes Here&amp;lt;/h1&amp;gt;\n&amp;lt;b&amp;gt;Bolded Text&amp;lt;/b&amp;gt;\n...&lt;/td&gt;
      &lt;td&gt;titl goe her bold text it text but stil i run ...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;&amp;lt;h1&amp;gt;Title Goes Here&amp;lt;/h1&amp;gt;\n&amp;lt;b&amp;gt;Bolded Text&amp;lt;/b&amp;gt;\n...&lt;/td&gt;
      &lt;td&gt;titl goe her bold text it text but stil i run ...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;&amp;lt;h1&amp;gt;Title Goes Here&amp;lt;/h1&amp;gt;\n&amp;lt;b&amp;gt;Bolded Text&amp;lt;/b&amp;gt;\n...&lt;/td&gt;
      &lt;td&gt;titl goe her bold text it text but stil i run ...&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;h2 id=&#34;parallelization-using-dask&#34;&gt;Parallelization using &lt;code&gt;dask&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;Care for some speed up using parallelization? No problem. &lt;code&gt;dask&lt;/code&gt; to the rescue. &lt;a href=&#34;https://docs.dask.org/en/latest/&#34; target=&#34;_blank&#34;&gt;(dask documents)&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import dask.dataframe as dd
from dask.multiprocessing import get
import timeit
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The idea here is we partition a pandas dataframe into &amp;ldquo;dask dataframe&amp;rdquo;, then we can run the job parallelly by putting different partition on different workers:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def dask_this(df):
    res = df[&#39;docs&#39;].apply(ct.do_all)
    return res  
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;ddata = dd.from_pandas(df, npartitions=10)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;type(ddata)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;dask.dataframe.core.DataFrame
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Doing a benchmark on our dataframes with 100 samples:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import time
start_time = time.time()
res = ddata.map_partitions(dask_this).compute(scheduler=&#39;processes&#39;, num_workers=10)
print(&amp;quot;--- %s seconds ---&amp;quot; % (time.time() - start_time))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;--- 1.2451355457305908 seconds ---
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import time
start_time = time.time()
res = df[&#39;docs&#39;].apply(ct.do_all)
print(&amp;quot;--- %s seconds ---&amp;quot; % (time.time() - start_time))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;--- 8.75901198387146 seconds ---
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;~7x speed up with 10 cores! Lets all start dasking!&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/sRKg9r2YWeCTG5JTTo/giphy.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
