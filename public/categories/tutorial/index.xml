<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tutorial on Think.Data.Science</title>
    <link>/categories/tutorial/</link>
    <description>Recent content in Tutorial on Think.Data.Science</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <copyright>{year}</copyright>
    <lastBuildDate>Tue, 03 Mar 2020 00:00:00 +0000</lastBuildDate>
    
	    <atom:link href="/categories/tutorial/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Python Tutorial of OSRM(Open Sourced Routing Machine) and Applications</title>
      <link>/post/2020-03-03-osrm/open-source-routing-machine-in-action-in-python-and-applications/</link>
      <pubDate>Tue, 03 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/2020-03-03-osrm/open-source-routing-machine-in-action-in-python-and-applications/</guid>
      <description>

&lt;p&gt;I came across a wonderful open source project recently &amp;mdash; Project OSRM (&lt;a href=&#34;http://project-osrm.org/&#34; target=&#34;_blank&#34;&gt;link&lt;/a&gt;) &amp;mdash; A modern C++ routing engine for shortest paths in road networks. You can imagine it as a free version of Google Maps API, without live traffic of course. It is very valuable for my work because my current company has large shipping and logistic services. Being able to calculate the distance and directions between locations in a timely fashion will enable us to research and modeling on route optimization, leads generation, etc.&lt;/p&gt;

&lt;p&gt;The solution itself is quite straightforward and I am able to setup an API sandbox running in a couple of hours.&lt;/p&gt;

&lt;p&gt;First you need to get the OSRM back-end running as a container on your machine. The process is very easy to follow on the project&amp;rsquo;s github page &lt;a href=&#34;https://github.com/Project-OSRM/osrm-backend&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;. After that you can easily interact with it in python, let&amp;rsquo;s take a look:&lt;/p&gt;

&lt;h2 id=&#34;package-needed&#34;&gt;Package Needed&lt;/h2&gt;

&lt;p&gt;We need &lt;code&gt;folium&lt;/code&gt; package to draw the routes on the map and &lt;code&gt;polyline&lt;/code&gt; to decode the routes from the API output. We will talk about that more later.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import requests
import folium
import polyline
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;single-request&#34;&gt;Single Request&lt;/h2&gt;

&lt;p&gt;You can request the driving route by supply the latitude and longitude of your start and end points, separate by  , and ;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;url = &amp;quot;http://10.22.168.65:9080/route/v1/driving/-117.851364,33.698206;-117.838925,33.672260&amp;quot;
r = requests.get(url)
res = r.json()
res
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;{&#39;code&#39;: &#39;Ok&#39;,
 &#39;routes&#39;: [{&#39;geometry&#39;: &#39;gttlEfyhnUpBtC|k@e`Aro@zo@tf@jXhFaMxSe]lDgKlAqIGwTcIyB&#39;,
   &#39;legs&#39;: [{&#39;steps&#39;: [],
     &#39;distance&#39;: 4995.3,
     &#39;duration&#39;: 409.1,
     &#39;summary&#39;: &#39;&#39;,
     &#39;weight&#39;: 422.5}],
   &#39;distance&#39;: 4995.3,
   &#39;duration&#39;: 409.1,
   &#39;weight_name&#39;: &#39;routability&#39;,
   &#39;weight&#39;: 422.5}],
 &#39;waypoints&#39;: [{&#39;hint&#39;: &#39;O14sgD1eLIAMAQAASQEAAAAAAAAAAAAAWs1fQprEiEIAAAAAAAAAAIYAAAClAAAAAAAAAAAAAACQBgAAnbv5-EQxAgIcu_n4njECAgAAfwLrq6bJ&#39;,
   &#39;distance&#39;: 15.580755,
   &#39;name&#39;: &#39;&#39;,
   &#39;location&#39;: [-117.851235, 33.698116]},
  {&#39;hint&#39;: &#39;S64XgFKuF4BLAAAAKgAAAAAAAAA_AAAA2iJQQqE95kEAAAAAb1YuQksAAAAqAAAAAAAAAD8AAACQBgAA5-z5-MXLAQKz6_n4RMwBAgAArwHrq6bJ&#39;,
   &#39;distance&#39;: 31.847501,
   &#39;name&#39;: &#39;Carlson Avenue&#39;,
   &#39;location&#39;: [-117.838617, 33.672133]}]}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The output is easy to follow. This trip has a distance of 4995 meters and travel time of 409 seconds, with the routes encoded using google&amp;rsquo;s &lt;a href=&#34;https://developers.google.com/maps/documentation/utilities/polylinealgorithm&#34; target=&#34;_blank&#34;&gt;Polyline Algorithm&lt;/a&gt;. We can use python package &lt;code&gt;polyline&lt;/code&gt; to decode it into coordinates:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;polyline.decode(&#39;gttlEfyhnUpBtC|k@e`Aro@zo@tf@jXhFaMxSe]lDgKlAqIGwTcIyB&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;[(33.69812, -117.85124),
 (33.69755, -117.85199),
 (33.69036, -117.84156),
 (33.68258, -117.84938),
 (33.67623, -117.85344),
 (33.67506, -117.85119),
 (33.67173, -117.84636),
 (33.67086, -117.8444),
 (33.67047, -117.84271),
 (33.67051, -117.83923),
 (33.67213, -117.83862)]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now this is something we can work with! Lets wrap it into a function:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def get_route(pickup_lon, pickup_lat, dropoff_lon, dropoff_lat):
    
    loc = &amp;quot;{},{};{},{}&amp;quot;.format(pickup_lon, pickup_lat, dropoff_lon, dropoff_lat)
    url = &amp;quot;http://10.22.168.65:9080/route/v1/driving/&amp;quot;
    r = requests.get(url + loc) 
    if r.status_code!= 200:
        return {}
  
    res = r.json()   
    routes = polyline.decode(res[&#39;routes&#39;][0][&#39;geometry&#39;])
    start_point = [res[&#39;waypoints&#39;][0][&#39;location&#39;][1], res[&#39;waypoints&#39;][0][&#39;location&#39;][0]]
    end_point = [res[&#39;waypoints&#39;][1][&#39;location&#39;][1], res[&#39;waypoints&#39;][1][&#39;location&#39;][0]]
    distance = res[&#39;routes&#39;][0][&#39;distance&#39;]
    
    out = {&#39;route&#39;:routes,
           &#39;start_point&#39;:start_point,
           &#39;end_point&#39;:end_point,
           &#39;distance&#39;:distance
          }

    return out
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pickup_lon, pickup_lat, dropoff_lon, dropoff_lat = -117.851364,33.698206,-117.838925,33.672260
test_route = get_route(pickup_lon, pickup_lat, dropoff_lon, dropoff_lat)
test_route
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;{&#39;route&#39;: [(33.69812, -117.85124),
  (33.69755, -117.85199),
  (33.69036, -117.84156),
  (33.68258, -117.84938),
  (33.67623, -117.85344),
  (33.67506, -117.85119),
  (33.67173, -117.84636),
  (33.67086, -117.8444),
  (33.67047, -117.84271),
  (33.67051, -117.83923),
  (33.67213, -117.83862)],
 &#39;start_point&#39;: [33.698116, -117.851235],
 &#39;end_point&#39;: [33.672133, -117.838617],
 &#39;distance&#39;: 4995.3}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;draw-the-route-on-map&#34;&gt;Draw the route on map&lt;/h2&gt;

&lt;p&gt;Now we have the output nicely organized in coordinates format, let&amp;rsquo;s use &lt;code&gt;folium&lt;/code&gt; package to chart the routes and see if it makes sense or not.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def get_map(route):
    
    m = folium.Map(location=[(route[&#39;start_point&#39;][0] + route[&#39;end_point&#39;][0])/2, 
                             (route[&#39;start_point&#39;][1] + route[&#39;end_point&#39;][1])/2], 
                   zoom_start=13)

    folium.PolyLine(
        route[&#39;route&#39;],
        weight=8,
        color=&#39;blue&#39;,
        opacity=0.6
    ).add_to(m)

    folium.Marker(
        location=route[&#39;start_point&#39;],
        icon=folium.Icon(icon=&#39;play&#39;, color=&#39;green&#39;)
    ).add_to(m)

    folium.Marker(
        location=route[&#39;end_point&#39;],
        icon=folium.Icon(icon=&#39;stop&#39;, color=&#39;red&#39;)
    ).add_to(m)

    return m
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;get_map(test_route)
&lt;/code&gt;&lt;/pre&gt;

&lt;div style=&#34;width:100%;&#34;&gt;&lt;div style=&#34;position:relative;width:100%;height:0;padding-bottom:60%;&#34;&gt;&lt;iframe src=&#34;data:text/html;charset=utf-8;base64,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&#34; style=&#34;position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;&#34; allowfullscreen webkitallowfullscreen mozallowfullscreen&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I just randomly pick two points in Irvine, CA and the route looks pretty good!&lt;/p&gt;

&lt;h2 id=&#34;benchmarking&#34;&gt;Benchmarking&lt;/h2&gt;

&lt;p&gt;If I want to use this API to processing data for me, I would like to know how fast it can handle my requests. Here I randomly generated another 1000 coordinates and request the routes from our docker backend as a mini stress test:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import numpy as np
import pandas as pd
lon1 = np.random.uniform(-117.4,-118, 1000).round(6)
lon2 = np.random.uniform(-117.4,-118, 1000).round(6)
lat1 = np.random.uniform(33.6,33.8, 1000).round(6)
lat2 = np.random.uniform(33.6,33.8, 1000).round(6)
df = pd.DataFrame({&#39;pickup_lon&#39;: lon1,
              &#39;pickup_lat&#39;: lat1,
              &#39;dropoff_lon&#39;: lon2,
              &#39;dropoff_lat&#39;: lat2,
             })
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df.head()
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;pickup_lon&lt;/th&gt;
      &lt;th&gt;pickup_lat&lt;/th&gt;
      &lt;th&gt;dropoff_lon&lt;/th&gt;
      &lt;th&gt;dropoff_lat&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;-117.650723&lt;/td&gt;
      &lt;td&gt;33.696095&lt;/td&gt;
      &lt;td&gt;-117.400615&lt;/td&gt;
      &lt;td&gt;33.675578&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;-117.653614&lt;/td&gt;
      &lt;td&gt;33.713656&lt;/td&gt;
      &lt;td&gt;-117.920080&lt;/td&gt;
      &lt;td&gt;33.679549&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;-117.484076&lt;/td&gt;
      &lt;td&gt;33.671013&lt;/td&gt;
      &lt;td&gt;-117.960667&lt;/td&gt;
      &lt;td&gt;33.741495&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;-117.599436&lt;/td&gt;
      &lt;td&gt;33.656727&lt;/td&gt;
      &lt;td&gt;-117.481877&lt;/td&gt;
      &lt;td&gt;33.643613&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;-117.968429&lt;/td&gt;
      &lt;td&gt;33.776134&lt;/td&gt;
      &lt;td&gt;-117.469914&lt;/td&gt;
      &lt;td&gt;33.739116&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%%time
df[&#39;routes&#39;] = df.apply(lambda x: get_route(x[&#39;pickup_lon&#39;], 
                                            x[&#39;pickup_lat&#39;],
                                            x[&#39;dropoff_lon&#39;], 
                                            x[&#39;dropoff_lat&#39;]), axis=1)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;CPU times: user 1.55 s, sys: 118 ms, total: 1.67 s
Wall time: 5.72 s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Not bad at all! With single container and it can finish the request async in 6 seconds. If we put it on a multiple node docker swarm cluster with proper load balancer, I believe the performance will be very staisfactory.&lt;/p&gt;

&lt;p&gt;Check with a random data I requested:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;get_map(df.loc[900,&#39;routes&#39;])
&lt;/code&gt;&lt;/pre&gt;

&lt;div style=&#34;width:100%;&#34;&gt;&lt;div style=&#34;position:relative;width:100%;height:0;padding-bottom:60%;&#34;&gt;&lt;iframe src=&#34;data:text/html;charset=utf-8;base64,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&#34; style=&#34;position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;&#34; allowfullscreen webkitallowfullscreen mozallowfullscreen&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&#34;potential-applications&#34;&gt;Potential applications&lt;/h2&gt;

&lt;p&gt;Now we have seen the beauty of the OSRM. You can imagine how many use cases it could potentially has. I actually used it to generate features in one Kaggle competition &amp;mdash; NYC taxi fare prediction &lt;a href=&#34;https://www.kaggle.com/c/new-york-city-taxi-fare-prediction/overview&#34; target=&#34;_blank&#34;&gt;(link)&lt;/a&gt;. In this competition, you were asked to predict the taxi fares given some basic features including the pickup and dropoff coordinates. As we all know that Haversine distance is different than the actually driving distance, especially in NYC. My intuition is that using the predicted driving distance will increase the model accuracy. Because that is how the taxi fares are calculated anyway. I was absolutely right. By adding this trip distance to the data, I am able to achieve the score of 3.09 which is about &lt;sup&gt;300&lt;/sup&gt;&amp;frasl;&lt;sub&gt;1500&lt;/sub&gt; on the leaderboard, using just 10% of the data! (full dataset is too big to work with on my laptop) I will publish my detailed approach in the next posts if you are interested.&lt;/p&gt;

&lt;p&gt;So what are you waiting for? Starting routing now!&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/U4YEoSRgz5JtebnYqH/giphy.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Authenticating AWS (Signature V4) in R using Python Backend</title>
      <link>/post/2019-12-05-authenticating-aws-signature-v4-in-r-using-python-backend/</link>
      <pubDate>Thu, 05 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019-12-05-authenticating-aws-signature-v4-in-r-using-python-backend/</guid>
      <description>


&lt;div id=&#34;intuition&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Intuition&lt;/h2&gt;
&lt;p&gt;I was working with an Elasticsearch project on AWS using Python and the &lt;code&gt;requests_aws4auth&lt;/code&gt; package worked like a charm for me. Never had any issue regarding the authentication (AWS V4 could be hard to work with sometimes). However, when I trying to create a Shiny app for my project, the problem emerged. I just couldn’t get the V4 auth to work with &lt;code&gt;httr&lt;/code&gt; in R. I tried &lt;code&gt;aws.signature&lt;/code&gt; package on &lt;a href=&#34;https://github.com/cloudyr/aws.signature&#34;&gt;Github&lt;/a&gt; but keep getting request header issues. Then I remembered that JJ Alaire from Rstudio created this amazing package &lt;code&gt;reticulate&lt;/code&gt; &lt;a href=&#34;https://rstudio.github.io/reticulate/&#34;&gt;(link)&lt;/a&gt; claiming the ability to import Python packages into R. Therefore I am intrigued to give it a try!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-syntax&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The Syntax&lt;/h2&gt;
&lt;p&gt;After install this package, the actually syntax is quite simple.&lt;/p&gt;
&lt;p&gt;Load the package and point it to the location of your Python (I’m using Ubuntu here):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(reticulate)
use_python(&amp;quot;/usr/local/bin/python&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then you can easily load and call Python functions! For example, a simple &lt;code&gt;listdir&lt;/code&gt; function from &lt;code&gt;os&lt;/code&gt; package:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;os &amp;lt;- import(&amp;quot;os&amp;quot;)
os$listdir(&amp;quot;.&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;index.html&amp;quot;   &amp;quot;featured.png&amp;quot; &amp;quot;index.Rmd&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;in-shiny&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;In Shiny&lt;/h2&gt;
&lt;p&gt;All I did was adding those to the &lt;code&gt;global.R&lt;/code&gt; script (the script I source first in &lt;code&gt;server.R&lt;/code&gt;)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;py_awsauth &amp;lt;- import(&amp;quot;requests_aws4auth&amp;quot;)
py_requests &amp;lt;- import(&amp;quot;requests&amp;quot;)

region &amp;lt;- &amp;#39;us-east-2&amp;#39;
service &amp;lt;- &amp;#39;execute-api&amp;#39;
credentials &amp;lt;- aws.signature::locate_credentials()
authr &amp;lt;- py_awsauth$AWS4Auth(credentials$key, credentials$secret, region, service, session_token=credentials$session_token)
url &amp;lt;- &amp;#39;https://.....&amp;#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see I am setting up the AWS connection using my local stored credentials. And the next step is to send HTTP request using Python &lt;code&gt;requests&lt;/code&gt; package.&lt;/p&gt;
&lt;p&gt;One thing to noticed is that you cannot use nested list for your payload as you would do that if you are using R &lt;code&gt;httr&lt;/code&gt; package. You have to create a Python dictionary object as your payload using &lt;code&gt;reticulate::py_dict()&lt;/code&gt; function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;
params &amp;lt;- reticulate::py_dict(c(&amp;quot;x&amp;quot;, &amp;quot;y&amp;quot;),
                              c(...,...))
response &amp;lt;- py_requests$get(url, auth = authr,params = params)
res &amp;lt;- response$json()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It worked like magic!&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/14udF3WUwwGMaA/giphy.gif&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;thoughts&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Thoughts&lt;/h2&gt;
&lt;p&gt;This is a good example of why I always encouraging Data Scientist to learn both R and Python. Many people only proficient in one and often has biased opinion against the other. Why not learn both so you can use the amazing package in R like &lt;code&gt;shiny&lt;/code&gt; and equivalently amazing packages like &lt;code&gt;ortools&lt;/code&gt; (I will write another post on this) at the same time!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Preprocess Text in Python --- A Cleaner and Faster Approach</title>
      <link>/post/preprocess-your-text-for-nlp-models-cleaner/</link>
      <pubDate>Thu, 04 Jul 2019 20:14:43 +0000</pubDate>
      
      <guid>/post/preprocess-your-text-for-nlp-models-cleaner/</guid>
      <description>

&lt;h2 id=&#34;motivation&#34;&gt;Motivation&lt;/h2&gt;

&lt;p&gt;Well, I think it all start with one of my favorite tweets from 2013:&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;en&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;In Data Science, 80% of time spent prepare data, 20% of time spent complain about need for prepare data.&lt;/p&gt;&amp;mdash; Big Data Borat (@BigDataBorat) &lt;a href=&#34;https://twitter.com/BigDataBorat/status/306596352991830016?ref_src=twsrc%5Etfw&#34;&gt;February 27, 2013&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;When building NLP models, pre-processing your data is extremely important. For example, different stopwords removal, stemming and lemmization might have huge impact on the accuracy of your models. Often times, the order of how you do the cleaning is also critical. Do you want to remove certain words first then tokenize the text? Or tokenize then remove the tokens? What we need is a &lt;strong&gt;clear to understand&lt;/strong&gt; and yet &lt;strong&gt;flexiable&lt;/strong&gt; code to do the pre-processing job. When using R, the pipe operator &lt;code&gt;%&amp;gt;%&lt;/code&gt; kind of taken care of the most part. However, there is no really good equivlent in Python because the natural different of Python and R: &lt;a href=&#34;https://medium.com/@jondot/functional-programming-with-python-for-people-without-time-1eebdbd9526c&#34; target=&#34;_blank&#34;&gt;(Long but very good read)&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;In other words, it’s like saying that when OOP was born, it was also born with the Gang-of-Four design patterns baked into it’s core as its backing theory of thought (outside of types and inheritance and methods etc.), and every implemented OOP language included these patterns and abstractions by default for you to take advantage of, and that these patterns were bullet-proofed by centuries of research. But that can already never be correct — the Singleton pattern is by now widely recognized as an anti-pattern, and GoF authors said they would remove it, if only they could go back in time.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;But we can definitely hack our way around this using Python &lt;strong&gt;Class&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;design&#34;&gt;Design&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s create a snippet of text as an example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;sample = &amp;quot;&amp;quot;&amp;quot;&amp;lt;h1&amp;gt;Title Goes Here&amp;lt;/h1&amp;gt;
&amp;lt;b&amp;gt;Bolded Text&amp;lt;/b&amp;gt;
&amp;lt;i&amp;gt;Italicized Text&amp;lt;/i&amp;gt;
&amp;lt;img src=&amp;quot;this should all be gone&amp;quot;/&amp;gt;
&amp;lt;a href=&amp;quot;this will be gone, too&amp;quot;&amp;gt;But this will still be here!&amp;lt;/a&amp;gt;
I run. He ran. She is running. Will they stop running?
I talked. She was talking. They talked to them about running. Who ran to the talking runner?
[Some text we don&#39;t want to keep is in here]
¡Sebastián, Nicolás, Alejandro and Jéronimo are going to the store tomorrow morning!
something... is! wrong() with.,; this :: sentence.
I can&#39;t do this anymore. I didn&#39;t know them. Why couldn&#39;t you have dinner at the restaurant?
My favorite movie franchises, in order: Indiana Jones; Marvel Cinematic Universe; Star Wars; Back to the Future; Harry Potter.
Don&#39;t do it.... Just don&#39;t. Billy! I know what you&#39;re doing. This is a great little house you&#39;ve got here.
[This is some other unwanted text]
John: &amp;quot;Well, well, well.&amp;quot;
James: &amp;quot;There, there. There, there.&amp;quot;
&amp;amp;nbsp;&amp;amp;nbsp;
There are a lot of reasons not to do this. There are 101 reasons not to do it. 1000000 reasons, actually.
I have to go get 2 tutus from 2 different stores, too.
22    45   1067   445
{{Here is some stuff inside of double curly braces.}}
{Here is more stuff in single curly braces.}
[DELETE]
&amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;&amp;quot;&amp;quot;&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Say you want to strip some html characters and use regular expressions to remove open and close double brackets and anything in between them:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import re, string, unicodedata
from bs4 import BeautifulSoup

def strip_html(text):
    soup = BeautifulSoup(text, &amp;quot;html.parser&amp;quot;)
    return soup.get_text()

def remove_between_square_brackets(text):
    return re.sub(&#39;\[[^]]*\]&#39;, &#39;&#39;, text)

def denoise_text(text):
    text = strip_html(text)
    text = remove_between_square_brackets(text)
    return text

sample = denoise_text(sample)
print(sample)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;    Title Goes Here
    Bolded Text
    Italicized Text
    
    But this will still be here!
    I run. He ran. She is running. Will they stop running?
    I talked. She was talking. They talked to them about running. Who ran to the talking runner?
    
    ¡Sebastián, Nicolás, Alejandro and Jéronimo are going to the store tomorrow morning!
    something... is! wrong() with.,; this :: sentence.
    I can&#39;t do this anymore. I didn&#39;t know them. Why couldn&#39;t you have dinner at the restaurant?
    My favorite movie franchises, in order: Indiana Jones; Marvel Cinematic Universe; Star Wars; Back to the Future; Harry Potter.
    Don&#39;t do it.... Just don&#39;t. Billy! I know what you&#39;re doing. This is a great little house you&#39;ve got here.
    
    John: &amp;quot;Well, well, well.&amp;quot;
    James: &amp;quot;There, there. There, there.&amp;quot;
    
    There are a lot of reasons not to do this. There are 101 reasons not to do it. 1000000 reasons, actually.
    I have to go get 2 tutus from 2 different stores, too.
    22    45   1067   445
    {{Here is some stuff inside of double curly braces.}}
     {Here is more stuff in single curly braces.}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This perfectly demonstrates our normal workflow:
1. Define couple of functions like &lt;code&gt;strip_html()&lt;/code&gt;, &lt;code&gt;remove_punctuation()&lt;/code&gt; &amp;hellip;
2. Run them one by one or define another &amp;ldquo;master function&amp;rdquo; to run them all like above example
3. Found that we need add more functions or change the order of the function runs
4. Make changes to the &amp;ldquo;master function&amp;rdquo; by copy and paste, then re-define it
5. Run new &amp;ldquo;master function&amp;rdquo; on the text
6. Rinse and repeat&lt;/p&gt;

&lt;p&gt;It is not very flexiable and easy to maintain, isn&amp;rsquo;t it?&lt;/p&gt;

&lt;h2 id=&#34;solution&#34;&gt;Solution&lt;/h2&gt;

&lt;p&gt;If we put those functions in a Class and let the function return &lt;code&gt;self&lt;/code&gt;, we can use the dot notation &lt;code&gt;.&lt;/code&gt; to chain them together, at any order!&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class cleantext():
    
    def __init__(self, text = None):
        self.text = text
        
    def strip_html(self):
        soup = BeautifulSoup(self.text, &amp;quot;html.parser&amp;quot;)
        self.text = soup.get_text()
        return self

    def remove_between_square_brackets(self):
        self.text = re.sub(&#39;\[[^]]*\]&#39;, &#39;&#39;, self.text)
        return self

    def remove_numbers(self):
        self.text = re.sub(&#39;[-+]?[0-9]+&#39;, &#39;&#39;, self.text)
        return self
    
    def do_all(self, text):
        
        self.text = text
        self = self.strip_html()
        self = self.remove_numbers()
       
        return self.words


&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;ct = cleantext(sample)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print(ct.strip_html().remove_between_square_brackets().remove_numbers().text)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;    Title Goes Here
    Bolded Text
    Italicized Text
    
    But this will still be here!
    I run. He ran. She is running. Will they stop running?
    I talked. She was talking. They talked to them about running. Who ran to the talking runner?
    
    ¡Sebastián, Nicolás, Alejandro and Jéronimo are going to the store tomorrow morning!
    something... is! wrong() with.,; this :: sentence.
    I can&#39;t do this anymore. I didn&#39;t know them. Why couldn&#39;t you have dinner at the restaurant?
    My favorite movie franchises, in order: Indiana Jones; Marvel Cinematic Universe; Star Wars; Back to the Future; Harry Potter.
    Don&#39;t do it.... Just don&#39;t. Billy! I know what you&#39;re doing. This is a great little house you&#39;ve got here.
    
    John: &amp;quot;Well, well, well.&amp;quot;
    James: &amp;quot;There, there. There, there.&amp;quot;
    
    There are a lot of reasons not to do this. There are  reasons not to do it.  reasons, actually.
    I have to go get  tutus from  different stores, too.
              
    {{Here is some stuff inside of double curly braces.}}
    {Here is more stuff in single curly braces.}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This makes our code readable and easy to manipulate. We can read out our code too &amp;mdash; just read the dot &lt;code&gt;.&lt;/code&gt; as &amp;ldquo;then&amp;rdquo; in your mind :
&amp;gt; sample text &lt;strong&gt;then&lt;/strong&gt; strip html &lt;strong&gt;then&lt;/strong&gt; remove between square brackets &lt;strong&gt;then&lt;/strong&gt; remove numbers&amp;rdquo;&lt;/p&gt;

&lt;h2 id=&#34;full-implementation&#34;&gt;Full implementation&lt;/h2&gt;

&lt;p&gt;So my full definition of the class looks like this: (example and many functions are from KDNugget)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import re, string, unicodedata
import nltk
import contractions
import inflect
from bs4 import BeautifulSoup
from nltk import word_tokenize, sent_tokenize
from nltk.corpus import stopwords
from nltk.stem import LancasterStemmer, WordNetLemmatizer

class cleantext():
    
    def __init__(self, text = &amp;quot;test&amp;quot;):
        self.text = text
        
    def strip_html(self):
        soup = BeautifulSoup(self.text, &amp;quot;html.parser&amp;quot;)
        self.text = soup.get_text()
        return self

    def remove_between_square_brackets(self):
        self.text = re.sub(&#39;\[[^]]*\]&#39;, &#39;&#39;, self.text)
        return self

    def remove_numbers(self):
        self.text = re.sub(&#39;[-+]?[0-9]+&#39;, &#39;&#39;, self.text)
        return self

    def replace_contractions(self):
        &amp;quot;&amp;quot;&amp;quot;Replace contractions in string of text&amp;quot;&amp;quot;&amp;quot;
        self.text = contractions.fix(self.text)
        return self
    
    def get_words(self):
        self.words = nltk.word_tokenize(self.text)
        return self

    def remove_non_ascii(self):
        &amp;quot;&amp;quot;&amp;quot;Remove non-ASCII characters from list of tokenized words&amp;quot;&amp;quot;&amp;quot;
        new_words = []
        for word in self.words:
            new_word = unicodedata.normalize(&#39;NFKD&#39;, word).encode(&#39;ascii&#39;, &#39;ignore&#39;).decode(&#39;utf-8&#39;, &#39;ignore&#39;)
            new_words.append(new_word)
        self.words = new_words
        return self

    def to_lowercase(self):
        &amp;quot;&amp;quot;&amp;quot;Convert all characters to lowercase from list of tokenized words&amp;quot;&amp;quot;&amp;quot;
        new_words = []
        for word in self.words:
            new_word = word.lower()
            new_words.append(new_word)
        self.words = new_words
        return self

    def remove_punctuation(self):
        &amp;quot;&amp;quot;&amp;quot;Remove punctuation from list of tokenized words&amp;quot;&amp;quot;&amp;quot;
        new_words = []
        for word in self.words:
            new_word = re.sub(r&#39;[^\w\s]&#39;, &#39;&#39;, word)
            if new_word != &#39;&#39;:
                new_words.append(new_word)
        self.words = new_words
        return self

    def replace_numbers(self):
        &amp;quot;&amp;quot;&amp;quot;Replace all interger occurrences in list of tokenized words with textual representation&amp;quot;&amp;quot;&amp;quot;
        p = inflect.engine()
        new_words = []
        for word in self.words:
            if word.isdigit():
                new_word = p.number_to_words(word)
                new_words.append(new_word)
            else:
                new_words.append(word)
        self.words = new_words
        return self

    def remove_stopwords(self):
        &amp;quot;&amp;quot;&amp;quot;Remove stop words from list of tokenized words&amp;quot;&amp;quot;&amp;quot;
        new_words = []
        for word in self.words:
            if word not in stopwords.words(&#39;english&#39;):
                new_words.append(word)
        self.words = new_words
        return self

    def stem_words(self):
        &amp;quot;&amp;quot;&amp;quot;Stem words in list of tokenized words&amp;quot;&amp;quot;&amp;quot;
        stemmer = LancasterStemmer()
        stems = []
        for word in self.words:
            stem = stemmer.stem(word)
            stems.append(stem)
        self.words = stems
        return self

    def lemmatize_verbs(self):
        &amp;quot;&amp;quot;&amp;quot;Lemmatize verbs in list of tokenized words&amp;quot;&amp;quot;&amp;quot;
        lemmatizer = WordNetLemmatizer()
        lemmas = []
        for word in self.words:
            lemma = lemmatizer.lemmatize(word, pos=&#39;v&#39;)
            lemmas.append(lemma)
        self.words = lemmas
        return self
    
    def join_words(self):
        self.words = &#39; &#39;.join(self.words)
        return self
    
    def do_all(self, text):
        
        self.text = text
        self = self.strip_html()
        self = self.remove_numbers()
        self = self.replace_contractions()
        self = self.get_words()
        self = self.remove_punctuation()
        self = self.remove_non_ascii()
        self = self.remove_stopwords()
        self = self.stem_words()
        self = self.lemmatize_verbs()
        self = self.join_words()
        
        return self.words
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we can pre-process our text easily, in a chain-like matter:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;ct = cleantext(sample)

ct.\
strip_html().\
remove_numbers().\
replace_contractions().\
get_words().\
remove_punctuation().\
remove_non_ascii().\
remove_stopwords().\
stem_words().\
lemmatize_verbs().\
join_words().\
words
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;&#39;titl goe her bold text it text but stil i run he run she run wil stop run i talk she talk they talk run who run talk run som text want keep sebast nicola alejandro jeronimo go stor tomorrow morn someth wrong send i anym i know why could din resta my favorit movy franch ord indian jon marvel cinem univers star war back fut harry pot just bil i know thi gre littl hous get thi unw text john wel wel wel jam ther ther ther lot reason ther reason reason act i go get tut diff stor her stuff insid doubl cur brac her stuff singl cur brac delet&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can easily add or modify any step on your code, it&amp;rsquo;s like a pipeline!&lt;/p&gt;

&lt;h2 id=&#34;apply-on-pandas-dataframe&#34;&gt;Apply on Pandas DataFrame&lt;/h2&gt;

&lt;p&gt;Say right now we have a dataframe and one column contains the string we would like to process. We can easily use &lt;code&gt;apply()&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import pandas as pd
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df = pd.DataFrame({&#39;id&#39;: range(0,100), &#39;docs&#39;:sample } )
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df.head()
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;id&lt;/th&gt;
      &lt;th&gt;docs&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;&amp;lt;h1&amp;gt;Title Goes Here&amp;lt;/h1&amp;gt;\n&amp;lt;b&amp;gt;Bolded Text&amp;lt;/b&amp;gt;\n...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;&amp;lt;h1&amp;gt;Title Goes Here&amp;lt;/h1&amp;gt;\n&amp;lt;b&amp;gt;Bolded Text&amp;lt;/b&amp;gt;\n...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;&amp;lt;h1&amp;gt;Title Goes Here&amp;lt;/h1&amp;gt;\n&amp;lt;b&amp;gt;Bolded Text&amp;lt;/b&amp;gt;\n...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;&amp;lt;h1&amp;gt;Title Goes Here&amp;lt;/h1&amp;gt;\n&amp;lt;b&amp;gt;Bolded Text&amp;lt;/b&amp;gt;\n...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;&amp;lt;h1&amp;gt;Title Goes Here&amp;lt;/h1&amp;gt;\n&amp;lt;b&amp;gt;Bolded Text&amp;lt;/b&amp;gt;\n...&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df[&#39;cleaned_docs&#39;] = df[&#39;docs&#39;].apply(ct.do_all)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df.head()
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;id&lt;/th&gt;
      &lt;th&gt;docs&lt;/th&gt;
      &lt;th&gt;cleaned_docs&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;&amp;lt;h1&amp;gt;Title Goes Here&amp;lt;/h1&amp;gt;\n&amp;lt;b&amp;gt;Bolded Text&amp;lt;/b&amp;gt;\n...&lt;/td&gt;
      &lt;td&gt;titl goe her bold text it text but stil i run ...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;&amp;lt;h1&amp;gt;Title Goes Here&amp;lt;/h1&amp;gt;\n&amp;lt;b&amp;gt;Bolded Text&amp;lt;/b&amp;gt;\n...&lt;/td&gt;
      &lt;td&gt;titl goe her bold text it text but stil i run ...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;&amp;lt;h1&amp;gt;Title Goes Here&amp;lt;/h1&amp;gt;\n&amp;lt;b&amp;gt;Bolded Text&amp;lt;/b&amp;gt;\n...&lt;/td&gt;
      &lt;td&gt;titl goe her bold text it text but stil i run ...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;&amp;lt;h1&amp;gt;Title Goes Here&amp;lt;/h1&amp;gt;\n&amp;lt;b&amp;gt;Bolded Text&amp;lt;/b&amp;gt;\n...&lt;/td&gt;
      &lt;td&gt;titl goe her bold text it text but stil i run ...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;&amp;lt;h1&amp;gt;Title Goes Here&amp;lt;/h1&amp;gt;\n&amp;lt;b&amp;gt;Bolded Text&amp;lt;/b&amp;gt;\n...&lt;/td&gt;
      &lt;td&gt;titl goe her bold text it text but stil i run ...&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;h2 id=&#34;parallelization-using-dask&#34;&gt;Parallelization using &lt;code&gt;dask&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;Care for some speed up using parallelization? No problem. &lt;code&gt;dask&lt;/code&gt; to the rescue. &lt;a href=&#34;https://docs.dask.org/en/latest/&#34; target=&#34;_blank&#34;&gt;(dask documents)&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import dask.dataframe as dd
from dask.multiprocessing import get
import timeit
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The idea here is we partition a pandas dataframe into &amp;ldquo;dask dataframe&amp;rdquo;, then we can run the job parallelly by putting different partition on different workers:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def dask_this(df):
    res = df[&#39;docs&#39;].apply(ct.do_all)
    return res  
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;ddata = dd.from_pandas(df, npartitions=10)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;type(ddata)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;dask.dataframe.core.DataFrame
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Doing a benchmark on our dataframes with 100 samples:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import time
start_time = time.time()
res = ddata.map_partitions(dask_this).compute(scheduler=&#39;processes&#39;, num_workers=10)
print(&amp;quot;--- %s seconds ---&amp;quot; % (time.time() - start_time))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;--- 1.2451355457305908 seconds ---
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import time
start_time = time.time()
res = df[&#39;docs&#39;].apply(ct.do_all)
print(&amp;quot;--- %s seconds ---&amp;quot; % (time.time() - start_time))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;--- 8.75901198387146 seconds ---
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;~7x speed up with 10 cores! Lets all start dasking!&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/sRKg9r2YWeCTG5JTTo/giphy.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
