{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivattion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, one of my favorate tweets from 2013:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">In Data Science, 80% of time spent prepare data, 20% of time spent complain about need for prepare data.</p>&mdash; Big Data Borat (@BigDataBorat) <a href=\"https://twitter.com/BigDataBorat/status/306596352991830016?ref_src=twsrc%5Etfw\">February 27, 2013</a></blockquote>\n",
       "<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">In Data Science, 80% of time spent prepare data, 20% of time spent complain about need for prepare data.</p>&mdash; Big Data Borat (@BigDataBorat) <a href=\"https://twitter.com/BigDataBorat/status/306596352991830016?ref_src=twsrc%5Etfw\">February 27, 2013</a></blockquote>\n",
    "<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When building NLP models, pre-processing your data is extremely necessary and important. For example, different stopwords removal, different stemming and lemmization might have huge impact on the accuracy of your models. Often times, the order of how you do the cleaning is also critical. Do you want to remove certain words first then tokenize? Or tokenize then remove? What we need is a clear to understand and yet flexiable code to do the pre-processing part. When using R, the pipe operator `%>%` kind of taken care of the most part. However, there is no really good equvilent in Python because the natural different of Python and R: [(Long but very good read)](https://medium.com/@jondot/functional-programming-with-python-for-people-without-time-1eebdbd9526c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In other words, it’s like saying that when OOP was born, it was also born with the Gang-of-Four design patterns baked into it’s core as its backing theory of thought (outside of types and inheritence and methods etc.), and every implemented OOP language included these patterns and abstractions by default for you to take advantage of, and that these patterns were bullet-proofed by centuries of research. But that can already never be correct — the Singleton pattern is by now widely recognized as an anti-pattern, and GoF authors said they would remove it, if only they could go back in time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we can definitely hack our way around this using Python **Class**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a snippt of text as an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"\"\"<h1>Title Goes Here</h1>\n",
    "<b>Bolded Text</b>\n",
    "<i>Italicized Text</i>\n",
    "<img src=\"this should all be gone\"/>\n",
    "<a href=\"this will be gone, too\">But this will still be here!</a>\n",
    "I run. He ran. She is running. Will they stop running?\n",
    "I talked. She was talking. They talked to them about running. Who ran to the talking runner?\n",
    "[Some text we don't want to keep is in here]\n",
    "¡Sebastián, Nicolás, Alejandro and Jéronimo are going to the store tomorrow morning!\n",
    "something... is! wrong() with.,; this :: sentence.\n",
    "I can't do this anymore. I didn't know them. Why couldn't you have dinner at the restaurant?\n",
    "My favorite movie franchises, in order: Indiana Jones; Marvel Cinematic Universe; Star Wars; Back to the Future; Harry Potter.\n",
    "Don't do it.... Just don't. Billy! I know what you're doing. This is a great little house you've got here.\n",
    "[This is some other unwanted text]\n",
    "John: \"Well, well, well.\"\n",
    "James: \"There, there. There, there.\"\n",
    "&nbsp;&nbsp;\n",
    "There are a lot of reasons not to do this. There are 101 reasons not to do it. 1000000 reasons, actually.\n",
    "I have to go get 2 tutus from 2 different stores, too.\n",
    "22    45   1067   445\n",
    "{{Here is some stuff inside of double curly braces.}}\n",
    "{Here is more stuff in single curly braces.}\n",
    "[DELETE]\n",
    "</body>\n",
    "</html>\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say you want to strip some html characters and use regular expressions to remove open and close double brackets and anything in between them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title Goes Here\n",
      "Bolded Text\n",
      "Italicized Text\n",
      "\n",
      "But this will still be here!\n",
      "I run. He ran. She is running. Will they stop running?\n",
      "I talked. She was talking. They talked to them about running. Who ran to the talking runner?\n",
      "\n",
      "¡Sebastián, Nicolás, Alejandro and Jéronimo are going to the store tomorrow morning!\n",
      "something... is! wrong() with.,; this :: sentence.\n",
      "I can't do this anymore. I didn't know them. Why couldn't you have dinner at the restaurant?\n",
      "My favorite movie franchises, in order: Indiana Jones; Marvel Cinematic Universe; Star Wars; Back to the Future; Harry Potter.\n",
      "Don't do it.... Just don't. Billy! I know what you're doing. This is a great little house you've got here.\n",
      "\n",
      "John: \"Well, well, well.\"\n",
      "James: \"There, there. There, there.\"\n",
      "  \n",
      "There are a lot of reasons not to do this. There are 101 reasons not to do it. 1000000 reasons, actually.\n",
      "I have to go get 2 tutus from 2 different stores, too.\n",
      "22    45   1067   445\n",
      "{{Here is some stuff inside of double curly braces.}}\n",
      "{Here is more stuff in single curly braces.}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re, string, unicodedata\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "\n",
    "def denoise_text(text):\n",
    "    text = strip_html(text)\n",
    "    text = remove_between_square_brackets(text)\n",
    "    return text\n",
    "\n",
    "sample = denoise_text(sample)\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This perfectly demostrates our normal workflow:\n",
    "1. Define couple of functions like `strip_html()`, `remove_punctuation()` ...\n",
    "2. Run them one by one or define another \"master function\" to run them all like above example\n",
    "3. Found that we need add more functions or change the order of the function runs\n",
    "4. Make changes to the \"master function\" by copy and paste, then re-define it\n",
    "5. Run new \"master function\" on the text\n",
    "6. Rinse and repeat\n",
    "\n",
    "It is not very flexiable and easy to do, isn't it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we put those functions in a Class and let the function return `self`, we can use the dot notation `.` to chain them together, at any order!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cleantext():\n",
    "    \n",
    "    def __init__(self, text = None):\n",
    "        self.text = text\n",
    "        \n",
    "    def strip_html(self):\n",
    "        soup = BeautifulSoup(self.text, \"html.parser\")\n",
    "        self.text = soup.get_text()\n",
    "        return self\n",
    "\n",
    "    def remove_between_square_brackets(self):\n",
    "        self.text = re.sub('\\[[^]]*\\]', '', self.text)\n",
    "        return self\n",
    "\n",
    "    def remove_numbers(self):\n",
    "        self.text = re.sub('[-+]?[0-9]+', '', self.text)\n",
    "        return self\n",
    "    \n",
    "    def do_all(self, text):\n",
    "        \n",
    "        self.text = text\n",
    "        self = self.strip_html()\n",
    "        self = self.remove_numbers()\n",
    "       \n",
    "        return self.words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = cleantext(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title Goes Here\n",
      "Bolded Text\n",
      "Italicized Text\n",
      "\n",
      "But this will still be here!\n",
      "I run. He ran. She is running. Will they stop running?\n",
      "I talked. She was talking. They talked to them about running. Who ran to the talking runner?\n",
      "\n",
      "¡Sebastián, Nicolás, Alejandro and Jéronimo are going to the store tomorrow morning!\n",
      "something... is! wrong() with.,; this :: sentence.\n",
      "I can't do this anymore. I didn't know them. Why couldn't you have dinner at the restaurant?\n",
      "My favorite movie franchises, in order: Indiana Jones; Marvel Cinematic Universe; Star Wars; Back to the Future; Harry Potter.\n",
      "Don't do it.... Just don't. Billy! I know what you're doing. This is a great little house you've got here.\n",
      "\n",
      "John: \"Well, well, well.\"\n",
      "James: \"There, there. There, there.\"\n",
      "  \n",
      "There are a lot of reasons not to do this. There are  reasons not to do it.  reasons, actually.\n",
      "I have to go get  tutus from  different stores, too.\n",
      "          \n",
      "{{Here is some stuff inside of double curly braces.}}\n",
      "{Here is more stuff in single curly braces.}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ct.strip_html().remove_between_square_brackets().remove_numbers().text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This makes our code very readable and easy to manipulate. We can read the dot `.` as \"then\" : \n",
    "> sample text **then** strip html **then** remove between square brackets **then** remove numbers\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So my full defination of the class looks like this: (exmple and many functions are from KDnugget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string, unicodedata\n",
    "import nltk\n",
    "import contractions\n",
    "import inflect\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "\n",
    "class cleantext():\n",
    "    \n",
    "    def __init__(self, text = \"test\"):\n",
    "        self.text = text\n",
    "        \n",
    "    def strip_html(self):\n",
    "        soup = BeautifulSoup(self.text, \"html.parser\")\n",
    "        self.text = soup.get_text()\n",
    "        return self\n",
    "\n",
    "    def remove_between_square_brackets(self):\n",
    "        self.text = re.sub('\\[[^]]*\\]', '', self.text)\n",
    "        return self\n",
    "\n",
    "    def remove_numbers(self):\n",
    "        self.text = re.sub('[-+]?[0-9]+', '', self.text)\n",
    "        return self\n",
    "\n",
    "    def replace_contractions(self):\n",
    "        \"\"\"Replace contractions in string of text\"\"\"\n",
    "        self.text = contractions.fix(self.text)\n",
    "        return self\n",
    "    \n",
    "    def get_words(self):\n",
    "        self.words = nltk.word_tokenize(self.text)\n",
    "        return self\n",
    "\n",
    "    def remove_non_ascii(self):\n",
    "        \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
    "        new_words = []\n",
    "        for word in self.words:\n",
    "            new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "            new_words.append(new_word)\n",
    "        self.words = new_words\n",
    "        return self\n",
    "\n",
    "    def to_lowercase(self):\n",
    "        \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
    "        new_words = []\n",
    "        for word in self.words:\n",
    "            new_word = word.lower()\n",
    "            new_words.append(new_word)\n",
    "        self.words = new_words\n",
    "        return self\n",
    "\n",
    "    def remove_punctuation(self):\n",
    "        \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "        new_words = []\n",
    "        for word in self.words:\n",
    "            new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "            if new_word != '':\n",
    "                new_words.append(new_word)\n",
    "        self.words = new_words\n",
    "        return self\n",
    "\n",
    "    def replace_numbers(self):\n",
    "        \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n",
    "        p = inflect.engine()\n",
    "        new_words = []\n",
    "        for word in self.words:\n",
    "            if word.isdigit():\n",
    "                new_word = p.number_to_words(word)\n",
    "                new_words.append(new_word)\n",
    "            else:\n",
    "                new_words.append(word)\n",
    "        self.words = new_words\n",
    "        return self\n",
    "\n",
    "    def remove_stopwords(self):\n",
    "        \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
    "        new_words = []\n",
    "        for word in self.words:\n",
    "            if word not in stopwords.words('english'):\n",
    "                new_words.append(word)\n",
    "        self.words = new_words\n",
    "        return self\n",
    "\n",
    "    def stem_words(self):\n",
    "        \"\"\"Stem words in list of tokenized words\"\"\"\n",
    "        stemmer = LancasterStemmer()\n",
    "        stems = []\n",
    "        for word in self.words:\n",
    "            stem = stemmer.stem(word)\n",
    "            stems.append(stem)\n",
    "        self.words = stems\n",
    "        return self\n",
    "\n",
    "    def lemmatize_verbs(self):\n",
    "        \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        lemmas = []\n",
    "        for word in self.words:\n",
    "            lemma = lemmatizer.lemmatize(word, pos='v')\n",
    "            lemmas.append(lemma)\n",
    "        self.words = lemmas\n",
    "        return self\n",
    "    \n",
    "    def join_words(self):\n",
    "        self.words = ' '.join(self.words)\n",
    "        return self\n",
    "    \n",
    "    def do_all(self, text):\n",
    "        \n",
    "        self.text = text\n",
    "        self = self.strip_html()\n",
    "        self = self.remove_numbers()\n",
    "        self = self.replace_contractions()\n",
    "        self = self.get_words()\n",
    "        self = self.remove_punctuation()\n",
    "        self = self.remove_non_ascii()\n",
    "        self = self.remove_stopwords()\n",
    "        self = self.stem_words()\n",
    "        self = self.lemmatize_verbs()\n",
    "        self = self.join_words()\n",
    "        \n",
    "        return self.words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can pre-process our text easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'titl goe her bold text it text but stil i run he run she run wil stop run i talk she talk they talk run who run talk run som text want keep sebast nicola alejandro jeronimo go stor tomorrow morn someth wrong send i anym i know why could din resta my favorit movy franch ord indian jon marvel cinem univers star war back fut harry pot just bil i know thi gre littl hous get thi unw text john wel wel wel jam ther ther ther lot reason ther reason reason act i go get tut diff stor her stuff insid doubl cur brac her stuff singl cur brac delet'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct = cleantext(sample)\n",
    "\n",
    "ct.\\\n",
    "strip_html().\\\n",
    "remove_numbers().\\\n",
    "replace_contractions().\\\n",
    "get_words().\\\n",
    "remove_punctuation().\\\n",
    "remove_non_ascii().\\\n",
    "remove_stopwords().\\\n",
    "stem_words().\\\n",
    "lemmatize_verbs().\\\n",
    "join_words().\\\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply on Pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say right now we have a dataframe and one column contains the string we would like to process. We can easily use `apply()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'id': range(0,100), 'docs':sample } )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;h1&gt;Title Goes Here&lt;/h1&gt;\\n&lt;b&gt;Bolded Text&lt;/b&gt;\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;h1&gt;Title Goes Here&lt;/h1&gt;\\n&lt;b&gt;Bolded Text&lt;/b&gt;\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;h1&gt;Title Goes Here&lt;/h1&gt;\\n&lt;b&gt;Bolded Text&lt;/b&gt;\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>&lt;h1&gt;Title Goes Here&lt;/h1&gt;\\n&lt;b&gt;Bolded Text&lt;/b&gt;\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>&lt;h1&gt;Title Goes Here&lt;/h1&gt;\\n&lt;b&gt;Bolded Text&lt;/b&gt;\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               docs\n",
       "0   0  <h1>Title Goes Here</h1>\\n<b>Bolded Text</b>\\n...\n",
       "1   1  <h1>Title Goes Here</h1>\\n<b>Bolded Text</b>\\n...\n",
       "2   2  <h1>Title Goes Here</h1>\\n<b>Bolded Text</b>\\n...\n",
       "3   3  <h1>Title Goes Here</h1>\\n<b>Bolded Text</b>\\n...\n",
       "4   4  <h1>Title Goes Here</h1>\\n<b>Bolded Text</b>\\n..."
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_docs'] = df['docs'].apply(ct.do_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>docs</th>\n",
       "      <th>cleaned_docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;h1&gt;Title Goes Here&lt;/h1&gt;\\n&lt;b&gt;Bolded Text&lt;/b&gt;\\n...</td>\n",
       "      <td>titl goe her bold text it text but stil i run ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;h1&gt;Title Goes Here&lt;/h1&gt;\\n&lt;b&gt;Bolded Text&lt;/b&gt;\\n...</td>\n",
       "      <td>titl goe her bold text it text but stil i run ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;h1&gt;Title Goes Here&lt;/h1&gt;\\n&lt;b&gt;Bolded Text&lt;/b&gt;\\n...</td>\n",
       "      <td>titl goe her bold text it text but stil i run ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>&lt;h1&gt;Title Goes Here&lt;/h1&gt;\\n&lt;b&gt;Bolded Text&lt;/b&gt;\\n...</td>\n",
       "      <td>titl goe her bold text it text but stil i run ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>&lt;h1&gt;Title Goes Here&lt;/h1&gt;\\n&lt;b&gt;Bolded Text&lt;/b&gt;\\n...</td>\n",
       "      <td>titl goe her bold text it text but stil i run ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               docs  \\\n",
       "0   0  <h1>Title Goes Here</h1>\\n<b>Bolded Text</b>\\n...   \n",
       "1   1  <h1>Title Goes Here</h1>\\n<b>Bolded Text</b>\\n...   \n",
       "2   2  <h1>Title Goes Here</h1>\\n<b>Bolded Text</b>\\n...   \n",
       "3   3  <h1>Title Goes Here</h1>\\n<b>Bolded Text</b>\\n...   \n",
       "4   4  <h1>Title Goes Here</h1>\\n<b>Bolded Text</b>\\n...   \n",
       "\n",
       "                                        cleaned_docs  \n",
       "0  titl goe her bold text it text but stil i run ...  \n",
       "1  titl goe her bold text it text but stil i run ...  \n",
       "2  titl goe her bold text it text but stil i run ...  \n",
       "3  titl goe her bold text it text but stil i run ...  \n",
       "4  titl goe her bold text it text but stil i run ...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelization using `dask`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Care for some speed up using parallelization? No problem. `dask` to the rescure. [(dask documents)](https://docs.dask.org/en/latest/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "from dask.multiprocessing import get\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea here is we partition a pandas dataframe into \"dask dataframe\", then we can run the job parallelly by putting different partition on different workers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dask_this(df):\n",
    "    res = df['docs'].apply(ct.do_all)\n",
    "    return res  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddata = dd.from_pandas(df, npartitions=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dask.dataframe.core.DataFrame"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ddata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing a benchmark on our dataframes with 100 samples: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.2451355457305908 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "res = ddata.map_partitions(dask_this).compute(scheduler='processes', num_workers=10)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 8.75901198387146 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "res = df['docs'].apply(ct.do_all)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~7x speed up with 10 cores! Lets all start dasking!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://giphy.com/embed/sRKg9r2YWeCTG5JTTo\" width=\"480\" height=\"480\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe><p><a href=\"https://giphy.com/gifs/running-run-runs-sRKg9r2YWeCTG5JTTo\">via GIPHY</a></p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<iframe src=\"https://giphy.com/embed/sRKg9r2YWeCTG5JTTo\" width=\"480\" height=\"480\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe><p><a href=\"https://giphy.com/gifs/running-run-runs-sRKg9r2YWeCTG5JTTo\">via GIPHY</a></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
